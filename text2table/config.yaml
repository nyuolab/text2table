tokenizer: 
  # the directory where the pretokenized data are stored
  ptk_dir_train: '../data/pretokenized/train/'
  ptk_dir_val: '../data/pretokenized/val/'
model:
  num_beams: 2
  max_length: 512
  min_length: 0
  length_penalty: 1.0
  early_stopping: true
trainer:
  gradient_checkpointing: true
  output_dir: '../../models/'
  predict_with_generate: true
  evaluation_strategy: 'steps'
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  fp16: true
  logging_steps: 10
  eval_steps: 1000
  save_steps: 1000
  save_total_limit: 2
  gradient_accumulation_steps: 4
  run_name: "mvp"
